# 10_적합대안 - 차원축소

#### **차원축소 방법**

**1. 주성분회귀**

- PCA는 변동이 크게 되는 새로운 축을 주성분으로 하여 데이터의 차원을 줄이는 기법이다.
- PCR기법은 설명변수 X를 가장 잘 나타내는 선형결합 또는 방향을 찾아내는 것이 관련된다. 이러한 방향들은 비지도 방식으로 식별된다.

**2. 부분최소제곱(PLS; partial least squares)**

- PCR처럼 차원축소 방법이며, 원래 변수들의 선형결합인 새로운 변수들의 집합을 먼저 찾은 다음 이 M개 새로운 변수들을 이용한 최소제곱을 통해 선형모델을 적합한다.
- 그러나 PCR과는 달리 PLS는 이러한 새로운 변수들을 **지도식 방식**으로 찾는다. 즉, PLS는 반응변수 Y를 이용하여 원래의 변수들을 잘 근사할 뿐만 아니라 반응변수와 관련이 있는 새로운 변수들을 식별한다.
- PLS는 디지털화된 분광분석 신호들로부터 많은 변수들이 발생되는 계량분석화학 분야에서 널리 사용된다.
- 실질적으로는 능형회귀나 PCR과 비슷한 성능을 보인다. PLS의 지도식 차원축소는 편향을 줄일 수 있지만 반면에 분산을 증가시킬 가능성이 있다.

<br>

---

<br>

#### **주성분회귀(PCR)**

```
library(pls)
set.seed(2)
pcr.fit=pcr(Salary~., data=Hitters, scale=TRUE, validation='CV')
summary(pcr.fit)
##Data:   X dimension: 263 19 
##        Y dimension: 263 1
##Fit method: svdpc
##Number of components considered: 19
##
##VALIDATION: RMSEP
##Cross-validated using 10 random segments.
##       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
##CV             452    351.9    353.2    355.0    352.8    348.4    343.6
##adjCV          452    351.6    352.7    354.4    352.1    347.6    342.7
##       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
##CV       345.5    347.7    349.6     351.4     352.1     353.5     358.2
##adjCV    344.7    346.7    348.5     350.1     350.7     352.0     356.5
##       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
##CV        349.7     349.4     339.9     341.6     339.2     339.6
##adjCV     348.0     347.7     338.2     339.7     337.2     337.6
##
##TRAINING: % variance explained
##        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
##X         38.31    60.16    70.84    79.03    84.29    88.63    92.26
##Salary    40.63    41.58    42.17    43.22    44.90    46.48    46.69
##        8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
##X         94.96    96.28     97.26     97.98     98.65     99.15     99.47
##Salary    46.75    46.86     47.76     47.82     47.85     48.10     50.40
##        15 comps  16 comps  17 comps  18 comps  19 comps
##X          99.75     99.89     99.97     99.99    100.00
##Salary     50.55     53.01     53.85     54.61     54.61

validationplot(pcr.fit, val.type="MSEP")
```

- 주성분회귀(PCR)은 pls라이브러리의 pcr함수를 사용하여 수행한다.
- validation='CV'를 설정하면 pcr은 사용된 주성분의 수 M에 대한 10-fold 교차검증 오차를 계산한다.
- 교차검증 결과는 validationplot 함수를 사용하여 그래프로 나타낼 수도 있다. val.type='MSEP'를 사용하면 교차검증 MSE가 그래프로 표현될 것이다.



![img](https://blog.kakaocdn.net/dn/bn62xU/btq3oSL5zgn/WvntKnmBMbACWf54cc5gPk/img.png)



- M=16일 때 교차검증 오차가 가장 작다. 이것은 M=19일 때와 거의 차이가 없다. M=19이면 단순히 최소제곱을 수행하는 것이된다.
- 하지만 그래프를 살펴보면 교차검증 오차는 하나의 성분만 포함하는 모델과 거의 같다는 것을 알 수 있다. 이것은 작은 수의 성분을 사용하는 모델이면 충분할 수 있다는 것을 시사한다.

```
set.seed(1)
pcr.fit=pcr(Salary~., data=Hitters, subsets=train, scale=TRUE, validation="CV")
validationplot(pcr.fit, val.type="MSEP")
```



![img](https://blog.kakaocdn.net/dn/OZrpV/btq3mZ6w09r/daYIQNSnkks5OKiUuYmtt1/img.png)



- 훈련셋에 대해 PCR을 수행하고 검정셋으로 성능을 평가한다. subset=train옵션으로 훈련셋의 인덱스를 지정해준다.
- 교차검증 오차가 가장 낮은 것은 M=7개의 주성분이 사용된 경우이다.

```
pcr.pred=predict(pcr.fit, x[test,], ncomp=7)
mean((pcr.pred-y.test)^2)
##[1] 119516.5
```

- 검정 MSE는 다음과 같이 계산한다.
- **PCR은 변수 선택을 수행하지 않고 심지어 직접적으로 계수 추정치도 제공하지 않기 때문에 모델 해석이 어렵다.**

```
pcr.fit=pcr(y~x, xcale=TRUE, ncomp=7)
summary(pcr.fit)
##Data:   X dimension: 263 19 
##        Y dimension: 263 1
##Fit method: svdpc
##Number of components considered: 7
##TRAINING: % variance explained
##   1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
##X    97.44    98.78    99.27    99.55    99.77    99.90    99.97
##y    28.15    37.22    38.23    43.61    43.70    43.77    48.07
```

- 교차검증에 의해 선택된 주성분의 수 M=7을 사용하여 PCR을 전체 자료에 적합한다.

#### **부분최소제곱(PLS)**

```
set.seed(1)
pls.fit=plsr(Salary~., data=Hitters, subset=train, scale=TRUE, validation="CV")
summary(pls.fit)
##Data:   X dimension: 131 19 
##        Y dimension: 131 1
##Fit method: kernelpls
##Number of components considered: 19
##
##VALIDATION: RMSEP
##Cross-validated using 10 random segments.
##       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
##CV           428.3    325.5    329.9    328.8    339.0    338.9    340.1
##adjCV        428.3    325.0    328.2    327.2    336.6    336.1    336.6
##       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
##CV       339.0    347.1    346.4     343.4     341.5     345.4     356.4
##adjCV    336.2    343.4    342.8     340.2     338.3     341.8     351.1
##       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
##CV        348.4     349.1     350.0     344.2     344.5     345.0
##adjCV     344.2     345.0     345.9     340.4     340.6     341.1
##
##TRAINING: % variance explained
##        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
##X         39.13    48.80    60.09    75.07    78.58    81.12    88.21
##Salary    46.36    50.72    52.23    53.03    54.07    54.77    55.05
##        8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
##X         90.71    93.17     96.05     97.08     97.61     97.97     98.70
##Salary    55.66    55.95     56.12     56.47     56.68     57.37     57.76
##        15 comps  16 comps  17 comps  18 comps  19 comps
##X          99.12     99.61     99.70     99.95    100.00
##Salary     58.08     58.17     58.49     58.56     58.62

validationplot(pls.fit, val.type="MSEP")
```



![img](https://blog.kakaocdn.net/dn/cfAJTm/btq3t4rtUlm/Nj3Syb84vwYhFuiBnGvCu0/img.png)



- 문법은 pcr과 동일하다.
- 가장 낮은 교차검증 오차는 M=2개의 부분최소제곱 방향이 사용된 경우에 발생한다.

```
pls.pred=predict(pls.fit, x[test,], ncomp=2)
mean((pls.pred-y.test)^2)
##[1] 145367.7
```

- 위의 결과에 대응하는 검정 MSE다.

```
pls.fit=plsr(Salary~., data=Hitters, scale=TRUE, ncomp=2)
summary(pls.fit)
##Data:   X dimension: 263 19 
##        Y dimension: 263 1
##Fit method: kernelpls
##Number of components considered: 2
##TRAINING: % variance explained
##        1 comps  2 comps
##X         38.08    51.03
##Salary    43.05    46.40
```

- 부분최소제곱을 전체 자료에 적합했다.
