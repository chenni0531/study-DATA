# 7_적합대안 - 변수선택

[TOC]

선형 회귀 모델 구축에 사용되는 최소제곱법이 아닌 다른 적합절차를 사용하는 이유

- 예측 정확도: n이 p보다 아주 크지 않으면 최소제곱적합에 많은 변동이 존재할 수 있어 과적합을 초래할 수 있다. p>n가 되면 분산이 무한대가 되어 최소제곱 방법은 전혀 사용할 수 없게 된다.
- 모델 해석력: 최소제곱방법으로 반응변수와 관련이 없는 변수들도 정확하게 0인 계수 추정치를 얻게 될 가능성은 거의 없다. 관련없는 변수들을 제외하는 기법들이 필요하다.

→ 서브셋(부분집합) 선택, 수축(shrinkage), 차원축소(Dimension Reduction)

<br>

**변수선택**: 선형 회귀 모델을 만들 때 주어진 여러 변수 중 어떤 변수를 설명 변수로 해야 할지 선택하는 과정으로 F 통계량이나 AIC 를 사용해 변수를 하나씩 택하거나 제거하는 것

**2. 중요 변수의 결정**

**모델의 quality를 평가하는 통계**

- 맬로우즈(Mallows) Cp
- AIC(Akaike information criterion)
- BIC(베이즈 정보기준, Bayesian information criterion)
- 수정된 R제곱

**3. 모델 적합**

- 모델 적합의 수치적 측도로 가장 흔히 사용되는 두 가지는 **RSE와 R제곱**

<br>

---

<br>

## 1. 최상의 부분집합 선택법

p개 설명변수의 모든 가능한 조합 각각에 대해 최소제곱회귀 적합 (2^p)

각 부분집합 크기에서 최고의 모델 (훈련데이터에 대해)을 식별하여 (p+1) 개의 모델 중에 하나 선택 

```
1. M0: null model
2. k = 1, 2, ..., p에 대해 k개의 설명변수를 포함하는 모든 pCk개의 모델 적합
3. pCk개의 모델 중 최고의 모델을 골라 Mk
4. M0, ..., Mk 중 최고의 모델 하나 선택
```

> 변수를 하나만 표함하겠다면 lstat를 포함한 모델이 가장 좋다

```r
> install.packages("leaps")
> library(leaps)

> m <- regsubsets(medv ~ ., data=BostonHousing)
> summary(m)

Subset selection object
Call: regsubsets.formula(medv ~ ., data = BostonHousing)
13 Variables  (and intercept)
        Forced in Forced out
crim        FALSE      FALSE
zn          FALSE      FALSE
indus       FALSE      FALSE
chas1       FALSE      FALSE
nox         FALSE      FALSE
rm          FALSE      FALSE
age         FALSE      FALSE
dis         FALSE      FALSE
rad         FALSE      FALSE
tax         FALSE      FALSE
ptratio     FALSE      FALSE
b           FALSE      FALSE
lstat       FALSE      FALSE
1 subsets of each size up to 8
Selection Algorithm: exhaustive
         crim zn  indus chas1 nox rm  age dis
1  ( 1 ) " "  " " " "   " "   " " " " " " " "
2  ( 1 ) " "  " " " "   " "   " " "*" " " " "
3  ( 1 ) " "  " " " "   " "   " " "*" " " " "
4  ( 1 ) " "  " " " "   " "   " " "*" " " "*"
5  ( 1 ) " "  " " " "   " "   "*" "*" " " "*"
6  ( 1 ) " "  " " " "   "*"   "*" "*" " " "*"
7  ( 1 ) " "  " " " "   "*"   "*" "*" " " "*"
8  ( 1 ) " "  "*" " "   "*"   "*" "*" " " "*"
         rad tax ptratio b   lstat
1  ( 1 ) " " " " " "     " " "*"  
2  ( 1 ) " " " " " "     " " "*"  
3  ( 1 ) " " " " "*"     " " "*"  
4  ( 1 ) " " " " "*"     " " "*"  
5  ( 1 ) " " " " "*"     " " "*"  
6  ( 1 ) " " " " "*"     " " "*"  
7  ( 1 ) " " " " "*"     "*" "*"  
8  ( 1 ) " " " " "*"     "*" "*" 
```

> BIC, 수정 결정계수 등의 값 확인

```r
> summary(m)$bic
[1] -385.0521 -496.2582 -549.4767 -561.9884 -585.6823
[6] -592.9553 -598.2295 -600.1663

> summary(m)$adjr2
[1] 0.5432418 0.6371245 0.6767036 0.6878351 0.7051702
[6] 0.7123567 0.7182560 0.7222072
```

```r
> plot(m, scale="adjr2")
```

![image-20210709104910777](8_적합대안_변수선택.assets/image-20210709104910777.png)

![image-20210709104947039](8_적합대안_변수선택.assets/image-20210709104947039.png)

<br>

---

<br>

## 2. 전진 선택법

> forawrd selection

- 더 이상 유의한 추가 변수가 없을 때까지 변수를 하나씩 추가
- 절편만 있는 모델에서 기준 통계치를 가장 많이 개선시키는 변수를 차례로 추가
- n < p인 경우에도 사용 가능

```
1. M0: null model
2. k = 1, 2, ..., p-1에 대해 Mk개에 하나의 설명변수를 추가한 모든 p-k개의 모델 고려
3. p-k개의 모델 중에서 최고를 골라 MK+1
4. M0, ..., Mp 중 최고의 모델 하나 선택
```

```
1. 고려된 변수 중 SSR(Xi)이 가장 높고 유의하면 변수를 선택한다
2. 이미 선택된 설명변수(Xi)의 설명부분 SSR을 제외한 SSR의 증가분 SSR(Xj|Xi)이 가장 크고 설명력이 유의한 경우 Xj 선택
3. 이미 선택된 설명변수(xi, Xj)의 설명부분 SSR을 제외한 SSR의 증가분 SSR(Xl|Xi, Xj)이 가장 크고 설명력이 유의한 경우 Xl 선택
4. 유의한 설명변수가 없을 때까지 반복
```

계산 시간이 빠르지만 선택된 설명변수는 절대 제거되지 않고 중요한 변수가 모형에 진입하지 못할 수도 있다

유의성 검정 과정 첨부

<br>

---

<br>

## 3. 후진 제거법

> Backward Elimination

- 유의하지 않은 독립변수들을 계속 제거
- 모든 변수가 포함된 모델에서 기준 통계치에 가장 도움이 되지 않는 변수를 하나씩 제거
- 표본의 수 n > 설명변수의 수 p (완전모델 적합이 가능해야한다)

```
1. M0: null model
2. k = p, p-1, ..., 1에 대해 Mk개에 하나의 설명변수를 제외한 모든 k개의 모델 고려
3. k개의 모델 중에서 최고를 골라 Mk-1
4. M0, ..., Mp 중 최고의 모델 하나 선택
```

```
1. 고려된 설명변수를 모두 삽입한 후 설명변수 중 가장 유의하지 않은 설명변수를 제거
2. 모든 설명변수가 유의할 때까지 반복
```

<br>

---

<br>

## 4. 단계적 선택

> Stepwise Selection

- 전진 선택법 + 후진 제거법

- 모든 변수가 포함된 모델 / 절편만 포함된 모델에서 출발
- 기준 통계치에 가장 도움이 되지 않는 변수를 삭제 / 빠져 있는 변수 중에서 기준 통계치를 가장 개선시키는 변수 추가

```
1. 고려된 설명 변수 중 설명력 SSR(Xi)이 가장 높고 설명력이 유의하면 변수 선택
2. 이미 선택된 설명변수의 설명부분을 제외한 SSR(Xj|Xi)이 가장 크고 설명력이 유의한 경우 Xj를 선택
3. 새로 선택된 변수의 설명부분을 제외한 부분에 대해 이미 존재한 설명변수의 유의성을 검정하여 유의하지 않으면 제외 / 유의하면 계속 넣고 다음 단계
4. 다시 이미 선택된 변수를 제외하고 다른 변수들 중 가장 SSR의 증가분이 높은 변수를 유의성 검정에 의해 유의하면 변수 추가
5. 유의한 설명변수가 존재하지 않을 때까지 반복
```

중요한 변수가 모형에서 제외될 가능성이 적은 비교적 안전한 방법이지만 한 번 제외된 변수는 다시 선택되지 못한다

<br>

---

<br>

> 보스턴의 집 가격 medv를 종속변수, 범죄율, 방의 수 등의 모든 변수를 독립변수 -> 변수의 추가 삭제를 반복하면서 최적의 모델 찾기
>
> step1: 13개의 변수 사용하고 AIC=1589.64
>
> 각 변수를 삭제했을 때 AIC의 변화 -> AIC를 가장 작게 만드는 변수를 삭제

```r
> install.packages("mlbench")
> library(mlbench)
> data("BostonHousing")

> m <- lm(medv ~ ., data=BostonHousing)
> m2 <- step(m, direction="both")

Start:  AIC=1589.64
medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + 
    tax + ptratio + b + lstat

          Df Sum of Sq   RSS    AIC
- age      1      0.06 11079 1587.7
- indus    1      2.52 11081 1587.8
<none>                 11079 1589.6
- chas     1    218.97 11298 1597.5
- tax      1    242.26 11321 1598.6
- crim     1    243.22 11322 1598.6
- zn       1    257.49 11336 1599.3
- b        1    270.63 11349 1599.8
- rad      1    479.15 11558 1609.1
- nox      1    487.16 11566 1609.4
- ptratio  1   1194.23 12273 1639.4
- dis      1   1232.41 12311 1641.0
- rm       1   1871.32 12950 1666.6
- lstat    1   2410.84 13490 1687.3
```

>step2: 12개의 변수 사용하고 AIC=1587.65
>
>각 변수를 삭제 / 추가했을 때 AIC의 변화 -> AIC를 가장 작게 만드는 변수를 삭제 / 추가

```r
Step:  AIC=1587.65
medv ~ crim + zn + indus + chas + nox + rm + dis + rad + tax + 
    ptratio + b + lstat

          Df Sum of Sq   RSS    AIC
- indus    1      2.52 11081 1585.8
<none>                 11079 1587.7
+ age      1      0.06 11079 1589.6
- chas     1    219.91 11299 1595.6
- tax      1    242.24 11321 1596.6
- crim     1    243.20 11322 1596.6
- zn       1    260.32 11339 1597.4
- b        1    272.26 11351 1597.9
- rad      1    481.09 11560 1607.2
- nox      1    520.87 11600 1608.9
- ptratio  1   1200.23 12279 1637.7
- dis      1   1352.26 12431 1643.9
- rm       1   1959.55 13038 1668.0
- lstat    1   2718.88 13798 1696.7
```

```r
Step:  AIC=1585.76
medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + 
    b + lstat

          Df Sum of Sq   RSS    AIC
<none>                 11081 1585.8
+ indus    1      2.52 11079 1587.7
+ age      1      0.06 11081 1587.8
- chas     1    227.21 11309 1594.0
- crim     1    245.37 11327 1594.8
- zn       1    257.82 11339 1595.4
- b        1    270.82 11352 1596.0
- tax      1    273.62 11355 1596.1
- rad      1    500.92 11582 1606.1
- nox      1    541.91 11623 1607.9
- ptratio  1   1206.45 12288 1636.0
- dis      1   1448.94 12530 1645.9
- rm       1   1963.66 13045 1666.3
- lstat    1   2723.48 13805 1695.0
```

<br>

---

<br>

## 5. 최량부분집합

> Best Subsets Regression

변수의 수가 1, 2, ..., k개 일 때, 각각 최고의 모형을 찾고 수정된 R2를 비교해서 최선의 모형을 선택

- 절약모형 (parsimonious model): 변수의 수를 고려한 비교에 의해 간단한 모형을 찾는다

- 변수의 수가 많으면 계산량이 매우 많아진다

<br>

---

<br>

## 실습

#### **최상의 서브셋 선택**

```
library(ISLR)
head(Hitters)
dim(Hitters)
##[1] 322  20
sum(is.na(Hitters$Salary))
##[1] 59

Hitters=na.omit(Hitters)
dim(Hitters)
##[1] 263  20
sum(is.na(Hitters$Salary))
##[1] 0
```

- Salary 변수에 누락된 선수 59명의 데이터 모두 제거

```
library(leaps)
regfit.full=regsubsets(Salary~., Hitters)
summary(regfit.full)
##Subset selection object
##Call: regsubsets.formula(Salary ~ ., Hitters)
##19 Variables  (and intercept)
##           Forced in Forced out
##AtBat          FALSE      FALSE
##Hits           FALSE      FALSE
##HmRun          FALSE      FALSE
##Runs           FALSE      FALSE
##RBI            FALSE      FALSE
##Walks          FALSE      FALSE
##Years          FALSE      FALSE
##CAtBat         FALSE      FALSE
##CHits          FALSE      FALSE
##CHmRun         FALSE      FALSE
##CRuns          FALSE      FALSE
##CRBI           FALSE      FALSE
##CWalks         FALSE      FALSE
##LeagueN        FALSE      FALSE
##DivisionW      FALSE      FALSE
##PutOuts        FALSE      FALSE
##Assists        FALSE      FALSE
##Errors         FALSE      FALSE
##NewLeagueN     FALSE      FALSE
##1 subsets of each size up to 8
##Selection Algorithm: exhaustive
##         AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
##1  ( 1 ) " "   " "  " "   " "  " " " "   " "   " "    " "   " "    " "  
##2  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
##3  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
##4  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
##5  ( 1 ) "*"   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
##6  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    " "  
##7  ( 1 ) " "   "*"  " "   " "  " " "*"   " "   "*"    "*"   "*"    " "  
##8  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   " "    " "   "*"    "*"  
##         CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
##1  ( 1 ) "*"  " "    " "     " "       " "     " "     " "    " "       
##2  ( 1 ) "*"  " "    " "     " "       " "     " "     " "    " "       
##3  ( 1 ) "*"  " "    " "     " "       "*"     " "     " "    " "       
##4  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
##5  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
##6  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
##7  ( 1 ) " "  " "    " "     "*"       "*"     " "     " "    " "       
##8  ( 1 ) " "  "*"    " "     "*"       "*"     " "     " "    " "        
```

- **leaps라이브러리에 포함된** **regsubsets함수**는 주어진 수의 설명변수를 포함하는 최고의 모델을 식별함으로써 최상의 서브셋을 선택한다. 여기서 최상 또는 최고는 RSS를 사용하여 수량화한다.

```
regfit.full=regsubsets(Salary~., data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)

par(mfrow=c(2, 2))
plot(reg.summary$rss, xlab='Number of Variables', ylab='RSS', type='l')
plot(reg.summary$adjr2, xlab='Number of Variables', ylab='Adjusted RSq', type='l')
points(which.max(reg.summary$adjr2), reg.summary$adjr2[11], col='red', cex=2, pch=20)
plot(reg.summary$cp, xlab='Number of Variables', ylab='Cp', type='l')
points(which.min(reg.summary$cp), reg.summary$cp[10], col='red', cex=2, pch=20)
plot(reg.summary$bic, xlab='Number of Variables', ylab='BIC', type='l')
points(which.min(reg.summary$bic), reg.summary$bic[6], col='red', cex=2, pch=20)
```



![img](https://blog.kakaocdn.net/dn/pCJGF/btq3md4vnHB/QlRc03xEwwBK91vlIlaKl1/img.png)



- regsubsets에 nvmax옵션을 사용해 원하는 변수 수만큼 결과를 얻을 수 있다.
- 모델에 대한 RSS, 조정된 R^2, Cp, BIC를 한꺼번에 그려 어느 모델을 선택할지 결정한다.

```
plot(regfit.full, scale='r2')
plot(regfit.full, scale='adjr2')
plot(regfit.full, scale='Cp')
plot(regfit.full, scale='bic')
```



![img](https://blog.kakaocdn.net/dn/dSj1mg/btq3n9l9wGW/GsMOluO9sjvNLRrYupjYvK/img.png)



- regsubsets함수는 내장된 plot함수를 가지며, 이것은 주어진 수의 설명변수를 갖는 최상의 모델에 포함되는 변수들을 나타내는 데 사용될 수 있다.

```
coef(regfit.full, 6)
## (Intercept)        AtBat         Hits        Walks         CRBI 
##  91.5117981   -1.8685892    7.6043976    3.6976468    0.6430169 
##   DivisionW      PutOuts 
##-122.9515338    0.2643076 
```

- 가장 낮은 BIC를 가지는 모델은 AtBat, Hits, Walk, CRBI, DivisionW, PutOuts만 포함하는 6-변수 모델이다. coef함수를 사용하여 이 모델과 관련된 계수 추정치를 확인할 수 있다.

#### **전진 및 후진 단계적 선택**

```
regfit.fwd=regsubsets(Salary~., data=Hitters, nvmax=19, method='forward')
summary(regfit.fwd)
regfit.bwd=regsubsets(Salary~., data=Hitters, nvmax=19, method='backward')
summary(regfit.bwd)

coef(regfit.full, 7)
## (Intercept)        AtBat         Hits        Walks         CRBI 
## 109.7873062   -1.9588851    7.4498772    4.9131401    0.8537622 
##      CWalks    DivisionW      PutOuts 
##  -0.3053070 -127.1223928    0.2533404 
coef(regfit.fwd, 7)
## (Intercept)        AtBat         Hits        Walks        CRuns 
## 105.6487488   -1.9762838    6.7574914    6.0558691    1.1293095 
##      CWalks    DivisionW      PutOuts 
##  -0.7163346 -116.1692169    0.3028847 
coef(regfit.bwd, 7)
## (Intercept)        AtBat         Hits        Walks        CRuns 
## 105.6487488   -1.9762838    6.7574914    6.0558691    1.1293095 
##      CWalks    DivisionW      PutOuts 
##  -0.7163346 -116.1692169    0.3028847 
```

- regsubsets함수는 method='forward', method='backward'를 사용하여 전진 또는 후진 단계적 선택을 수행하는 데도 사용할 수 있다.
- 전진 단계적 선택, 후진 단계적 선택, 최상의 서브셋 선택에 의해 식별된 최상의 7-변수 모델들은 서로 다른 것을 확인할 수 있다.

#### **검증셋 기법과 교차검증을 사용한 모델 선택**

```
set.seed(1)
train=sample(c(TRUE, FALSE), nrow(Hitters), rep=TRUE)
test=(!train)

regfit.best=regsubsets(Salary~., data=Hitters[train,], nvmax=19)
test.mat=model.matrix(Salary~., data=Hitters[test,])

val.errors=rep(NA, 19)
for (i in 1:19){
	coefi=coef(regfit.best, id=i)
	pred=test.mat[,names(coefi)]%*%coefi
	val.errors[i]=mean((Hitters$Salary[test]-pred)^2)}
val.errors
## [1] 164377.3 144405.5 152175.7 145198.4 137902.1 139175.7 126849.0 136191.4
## [9] 132889.6 135434.9 136963.3 140694.9 140690.9 141951.2 141508.2 142164.4
## [17] 141767.4 142339.6 142238.2

coef(regfit.best, which.min(val.errors))
##  (Intercept)        AtBat         Hits        Walks        CRuns 
##  67.1085369   -2.1462987    7.0149547    8.0716640    1.2425113 
##      CWalks    DivisionW      PutOuts 
##  -0.8337844 -118.4364998    0.2526925 
```

- model.matrix함수는 데이터를 모형행렬로 만들어주는 함수다.
- for문을 실행하여 모델에 대한 계수들을 regfit.best에서 추출하여 coefi에 저장하고, 이 계수들을 검정모델 행렬에 곱하여 예측값을 구하고 검정 MSE를 계산한다.

```
predict.regsubsets=function(object, newdata, id, ...){
	form=as.formula(object$call[[2]])
	mat=model.matrix(form, newdata)
	coefi=coef(object, id=id)
	xvars=names(coefi)
	mat[,xvars]%*%coefi}
```

- 이렇게 함수를 사용할 수도 있다. 실제로 적용할 때는 object에 regfit.best와 같은 모델 명을 입력하면 된다.

```
k=10
set.seed(1)
folds=sample(1:k, nrow(Hitters), replace=TRUE)
folds
##  [1]  9  4  7  1  2  7  2  3  1  5  5 10  6 10  7  9  5  5  9  9  5  5  2 10
## [25]  9  1  4  3  6 10 10  6  4  4 10  9  7  6  9  8  9  7  8  6 10  7  3 10
## [49]  6  8  2  2  6  6  1  3  3  8  6  7  6  8  7  1  4  8  9  9  7  4  7  6
## [73]  1  5  6  1  9  7  7  3  6  2 10 10  7  3  2 10  1 10 10  8 10  5  7  8
## [97]  5  6  8  1  3 10  3  1  6  6  4  9  5  1  3  6  3  7  3  3  1  9  2  8
##[121]  6  1  2  7  7  4  9  8  3  5  3  4  2  1  7  9 10 10  2  2  3  1  2  3
##[145]  3  3  8  9  2 10  8 10  4  5  9  5  7  5  6  4  2  1  3  8  9  6  1  4
##[169]  5  9  5  8  4  1  9  5  1  5  4 10 10  9  8  5  5  6  6  2  2  8  4 10
##[193]  8  5  5  8  8  7  4  4  1 10  4  9  9  9  9  6  6  4  3  3  9  9  7  9
##[217]  5  7  4  4 10  8  1 10  2 10  1  1  4  5  5  6  9  8  5  1  2  1  8  5
##[241]  8 10  7  7  2  9  4  2  5  2  4  3  6  9  7  5  5  1  1 10  1  3 10

cv.errors=matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))
cv.errors
##       1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
## [1,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [2,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [3,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [4,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [5,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [6,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [7,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [8,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [9,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
##[10,] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
```

- k-fold 교차검증을 사용하여 최상의 서브셋을 선택하기 위해, 10-fold 중 하나의 그룹에 할당하는 벡터와 그 결과를 저장할 행렬을 생성한다.

```
for (j in 1:k){
	best.fit=regsubsets(Salary~., data=Hitters[folds!=j,], nvmax=19)
	for (i in 1:19){
		pred=predict.regsubsets(best.fit, Hitters[folds==j, ], id=i)
		cv.errors[j, i]=mean((Hitters$Salary[folds==j]-pred)^2)
		}
	}
    
mean.cv.errors=apply(cv.errors, 2, mean)
mean.cv.errors
##       1        2        3        4        5        6        7        8 
##149821.1 130922.0 139127.0 131028.8 131050.2 119538.6 124286.1 113580.0 
##       9       10       11       12       13       14       15       16 
##115556.5 112216.7 113251.2 115755.9 117820.8 119481.2 120121.6 120074.3 
##      17       18       19 
##120084.8 120085.8 120403.5 
```

- for문을 통해 10*19행렬이 얻어지며, 원소(i, j)는 i번째 교차검증 fold와 최고의 j-변수 모델에 대한 검정MSE다.
- regsubsets함수에는 predict가 적용되지 않으므로 위에서 새롭게 만들어준 predict.regsubsets함수로 예측값을 구했다.
- apply함수를 이용해 이 행렬의 열별로 평균을 구하면 벡터가 얻어지는데, 이 벡터의 j번째 원소는 j-변수 모델에 대한 교차검증 오차다.

```
plot(mean.cv.errors, type='b')
```



![img](https://blog.kakaocdn.net/dn/nDo1i/btq3oTKDxB6/pyZeWSdM0p5up2SseYZZmk/img.png)



- 교차검증은 11-변수 모델을 선택한다.
