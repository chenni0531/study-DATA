# 4_회귀모형진단

[TOC]

## 1. 모형의 선형성

- 진단: 잔차 산점도가 선형인지 확인

- 처방: 비선형회귀모형을 설정하거나 변수변환을 하여 선형이 되도록 하기

<br>

---

<br>

## 2. 잔차 진단

**잔차(residuals)**: 남아있는 오차, 추정 회귀식이 반응변수 관찰치를 설명하지 못하는 부분

- 잔차 산점도 (Residual Plot)를 그렸을 때 평평한 띠 모양

- 오차항에 대한 가정 검토: 독립성, 정규성, 등분산성

<br>

### 2-1. 오차의 등분산성

- 진단: 잔차 산점도에서 띠 모양이 나오는지 확인
- 처방: 등분산이 되도록 모형을 조정하거나 이분산을 고려한 모형으로 바꾸기

<br>

### 2-2. 오차의 정규성

- 진단: 잔차의 히스토그램, 줄기잎그림을 그려 정규 분포 모양인지 확인
  - Shapiro-Wilk W 통계량
  - `Normal Q-Q plot`
- 처방: 변수변환을 하기

<br>

### 2-3. 오차의 독립성

- 진단: Durbin-watson 통계량

<br>

---

<br>

## 3. 이상치

**이상치 (Outlier)**: 주어진 회귀 모델에 의해 잘 설명되지 않는 데이터 점들 

**스튜던트화 잔차 (Studentized Residual)**: 잔차를 잔차의 표준편차로 나눈 값

- 진단: 잔차 (외면 스튜던트화 잔차)
- 처방: 입력 실수인지 확인, 이상치를 그대로 포함할지, 제거한 후 선형 모형을 적용할지 확인

**영향관찰치**: 영향력이 큰 이상치

- 진단: 영향력을 판단하기 위해 제거한 후 모형을 추정하고 추정치 값들과 R2가 얼마나 차이나는지 확인
- 처방: 입력 실수인지 확인

```r
> data(Orange)
> m <- lm(circumference ~ age + I(age^2), data=Orange)
> rstudent(m)
          1           2           3           4 
 0.19985287 -0.53303263 -0.17840851 -0.54325622 
          5           6           7           8 
-1.31082205 -0.92292494 -1.72799370  0.33615199 
          9          10          11          12 
-0.06394288  0.85316955  1.23124345  0.92915017 
         13          14          15          16 
 1.75080916  0.93486279  0.19985287 -0.83687327 
         17          18          19          20 
-0.69447869 -0.84791970 -1.54276649 -1.05591062 
         21          22          23          24 
-1.98782529  0.29066403 -0.36166980  0.89732592 
         25          26          27          28 
 1.75037512  1.24135751  2.05032759  1.45729711 
         29          30          31          32 
 0.19985287 -0.92493008 -0.43504980 -0.11561888 
         33          34          35 
-0.34906199  0.44471090 -0.23134075 
```

<br>

**본페로니 교정 (Bonferroni correction)**: 다중 비교에서 검정하는 가설의 숫자가 늘어나면 귀무가설이 기각될 확률이 낮더라도 기각될 가능성 더욱 늘어나게 된다. 귀무가설이 참임에도 불구하고 기각하는 제1종 오류를 보정하기 위해서 여러 개의 가설들에 대해서 최소한 하나의 제1종오류가 발생할 가능성을 계산해 보정할 수 있다. 

> 스튜던트화 잔차는 t분포를 따르므로 t-test를 사용해 `rstudent()` 값이 너무 크거나 작은 점을 찾기: 36번째 데이터에서 Bonferroni p < 0.05 이므로 이상치 검출

```r
> Orange <- rbind(Orange, data.frame(Tree=as.factor(c(6, 6, 6)), age=c(118, 484, 664), circumference=c(177, 50, 30)))
> tail(Orange)
   Tree  age circumference
33    5 1231           142
34    5 1372           174
35    5 1582           177
36    6  118           177
37    6  484            50
38    6  664            30
```

```r
> m <- lm(circumference ~ age + I(age^2), data=Orange)
> outlierTest(m)
   rstudent unadjusted p-value Bonferroni p
36 5.538438          3.429e-06    0.0001303
```

<br>

---

<br>

## 4. 다중공선성

**다중공선성 (Multicollinearity)**: X변수 중 하나와 다른 X 변수들의 선형결합이 매우 높은 상관관계에 있을 때 / X변수들 사이의 선형 독립성이 성립하지 못한 상태

- 다중공선성이 존재하면 X변수들의 기울기를 정확히 계산하지 못하거나 아예 계산이 되지 않는다

- 진단
  - 산점도 행렬 또는 설명 변수끼리의 산점도에서 거의 직선에 가까운 선형관계를 보이는 경우
  - 설명 변수를 뺄 때와 추가할 때 다른 설명변수들의 기울기 추정값들이 많이 변동하는 경우
  - ANOVA에 의해 유의적으로 기울기들이 모두 0이 아니지만 문제가 되는 X변수의 기울기는 유의적이지 않은 경우
  - 통계적 검정
- 처방: X변수들끼리 선형 독립성을 유지해야하므로 문제가 되는 X변수를 제거한다

<br>

---

<br>

## 5. 그래프

```r
plot(m)
```

`Residuals vs Fitted plot`

- X축 - 선형 회귀로 예측된 Y값, Y축 - 잔차

- 0에서 멀리 떨어진 값: 이상치 가능

![image-20210706175309436](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706175309436.png)

`Normal Q-Q plot`

![image-20210706175328632](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706175328632.png)

`Scale-Location plot`

- X축 - 선형 회귀로 예측된 Y값, Y축 - 표준화 잔차
- 0에서 멀리 떨어진 값: 이상치 가능

![image-20210706175340869](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706175340869.png)

`Residuals vs Leverage plot`

- X축 - 레버리지, Y축 - 표준화 잔차

- 레버리지: 설명변수가 얼마나 극단에 치우쳐 있는지
- 쿡의 거리 (Cook's Distance): 회귀 직선의 모양에 크게 영향을 끼치는 점들을 찾는 방법으로, 레버리지와 잔차에 비례 (우측 상단, 우측 하단)

![image-20210706175223296](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706175223296.png)

<br>

```r
plot(m, which=c(4, 6))
```

`Cook's distance`

![image-20210706235812906](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706235812906.png)

`Cook's dist vs Leverage`

![image-20210706235823326](C:/Users/USER/Desktop/chenni0531/Data Analysis/study-TIL/00_통계분석/1_회귀분석/1_선형회귀/1_단순선형회귀.assets/image-20210706235823326.png)



<br>

---

<br>

#### **선형회귀에서 중요한 몇 가지 질문**

**1. 반응변수와 설명변수 사이에 상관관계가 있는가?**

- p개의 설명변수가 있는 다중회귀에서는 모든 회귀계수들이 0인지, **F-통계량을 계산하여 가설검정**을 한다.
- n이 큰 경우에는 F-통계량이 1보다 약간만 크면 귀무가설(모든 회귀계수들이 0)에 반하는 증거가 된다. 반대로 n이 작은 경우 귀무가설을 기각하려면 더 큰 F-통계량이 필요하다.

#### **선형회귀모델 구축으로 발생할 수 있는 잠재적 문제**

**1. 데이터의 비선형성**

- 선형회귀모델은 설명변수들과 반응변수 사이에 직선 상관관계가 있다고 가정한다. 만약 실제 상관관계가 선형과 거리가 멀면 모든 결론이 의문스럽고 모델의 예측 정확도도 현저히 줄어들 수 있다.
- **잔차 그래프**(Residuals vs Fitted values 그래프)는 비선형성을 식별하는데 유용하다. 이상적이라면 잔차 그래프는 인지할만한 패턴을 보이지 않을 것이다. 패턴이 존재한다면 선형모델에 어떤 문제가 있을 수 있음을 나타낸다.
- 만약 잔차 그래프가 비선형 상관성이 있다는 것을 나타내면, **log, 루트, 제곱변환을 통해 설명변수X들을 비선형적으로 변환**하여 회귀모델에 적용하는 것이 간단한 접근법이다.

**2. 오차항들의 상관성**

- 선형회귀모델에서 중요한 가정은 오차항들이 서로 상관되어 있지 않다는 것이다.
- 만약 오차항들 사이에 상관성이 있으면 **추정된 표준오차는 실제 표준오차를 과소추정하는 경향**이 있을 것이다.
- 그 결과 **실질적인 신뢰구간과 예측구간은 계산된 수치보다 더 좁을 것**이다.
- 이러한 상관성은 이산 시점에 측정된 관측치들로 구성된 시계열 데이터에서 자주 발생된다.

**3. 오차항의 상수가 아닌 분산**

- 선형회귀모델에서 중요한 또 다른 가정은 오차항들의 분산이 상수라는 것이다.
- 오차의 비상수 분산 또는 이분산성은 잔차 그래프에 깔때기 형태가 있는지를 보고 식별할 수 있다.
- 이런 문제가 발생하면 **log, 제곱근과 같은 오목함수를 사용하여 반응변수Y를 변환**하는 것이 한 가지 해결책이다.

**4. 이상치**

- 이상치는 **y가 모델이 예측한 값과 크게 다른 점**이다. 이상치는 데이터를 수집할 때 관측치를 잘못 기록하는 것과 같이 다양한 원인에 의해 발생될 수 있다.
- 이상치는 설명변수 값이 특이한 것이 아니어서 보통 **최소제곱적합에 거의 영향을 미치지 못한다**. 기울기 변화가 거의 없고 절편은 아주 조금 줄어든다.
- 하지만 하나의 관측치에 의한 급격한 수치 증가는 **적합 해석에 영향을 줄 수 있다**. 예를 들어, 이상치가 회귀에 포함될 때의 RSE는 1.09지만 이상치를 제외하면 0.77밖에 되지 않는다. 마찬가지로 이상치를 포함하는 것은 설명계**수**를 0.892에서 0.805로 줄어들게 한다.
- **잔차 그래프**가 이상치를 식별하는 데 사용될 수 있다. 그러나 실제로는 어떤 점이 이상치라고 판단하려면 잔차가 얼마나 커야 하는지 결정하기 쉽지 않을 수 있다.
- 이 문제를 해결하기 위해 잔차 그래프 대신 **스튜던트화 잔차**를 그릴 수 있다. 이것은 **각 잔차를 추정표준오차로 나누어 계산**한다. 스튜던트화 잔차의 **절대값이 3보다 큰 관측치가 이상치**일 수 있다.

**5. 레버리지가 높은 (영향력이 큰) 관측치**



![img](https://blog.kakaocdn.net/dn/cYuHtq/btq1NtGQaik/7v3AwHCasCFxoB80JqB1w1/img.png)레버리지 통계량 계산식



- 높은 레버리지를 가지는 관측치는 대응하는 **x값이 보통 수준과 다른 것**을 뜻한다.
- 레버리지가 높은 관측치를 제외하는 것이 이상치를 제외하는 것보다 최소제곱선에 훨씬 더 큰 영향을 미치기 때문에, 높은 레버리지 관측치를 식별하는 것이 중요하다.
- 레버리지 통계량은 항상 1/n과 1 사이의 값이고 모든 관측치에 대한 평균 레버리지는 항상 (p+1)/n이다. 이보다 훨씬 큰 레버리지 통계량을 가지면 대응하는 점은 높은 레버리지를 가진다고 의심해 볼 수 있다.

**6. 공선성**

- 공선성은 두 개 또는 그 이상의 설명변수들이 서로 밀접하게 상관되어 있는 경우를 말한다.
- 공선성은 t-통계량을 줄인다. 그 결과 귀무가설(회귀계수는 0이다)을 기각하지 못할 수 있다. 이것이 의미하는 것은 가설검정의 능력(즉 영이 아닌 계수를 정확하게 검출할 확률)이 공선성에 의해 줄어든다는 것이다.
- **분산팽창인수(VIF, variance inflation factor)**를 계산하여 다중공선성을 판단한다. VIF의 가능한 가장 작은 값은 1이며, 공선성이 전혀 없음을 나타낸다. 경험적으로 5 또는 10을 초과하는 VIF값은 문제의 소지가 있을 정도의 공선성을 나타낸다.
- 공선성 문제가 있을 경우, **회귀에서 문제가 있는 변수들 중 하나를 제외**할 수 있다. 공선성이 있다는 것은 제외되는 변수가 반응변수에 대해 제공하는 정보가 다른 변수들과 중복된다는 것을 의미하기 때문이다.
- 공선성 문제가 있을 경우, **공선성 변수들을 단일 설명변수로 결합**하는 것도 하나의 방법이다.

------

### **R Code**

#### **데이터 준비**

```
library(MASS)
head(Boston)

##     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat medv
##1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98 24.0
##2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14 21.6
##3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03 34.7
##4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94 33.4
##5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33 36.2
##6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21 28.7
```

 

MASS 라이브러리 안에 있는 Boston 데이터를 사용한다.

#### **다중선형회귀**

```
lm.fit=lm(medv~., data=Boston)
summary(lm.fit)

##Call:
##lm(formula = medv ~ ., data = Boston)

##Residuals:
##    Min      1Q  Median      3Q     Max 
##-15.595  -2.730  -0.518   1.777  26.199 

##Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
##(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
##crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
##zn           4.642e-02  1.373e-02   3.382 0.000778 ***
##indus        2.056e-02  6.150e-02   0.334 0.738288    
##chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
##nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
##rm           3.810e+00  4.179e-01   9.116  < 2e-16 ***
##age          6.922e-04  1.321e-02   0.052 0.958229    
##dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
##rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
##tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
##ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
##black        9.312e-03  2.686e-03   3.467 0.000573 ***
##lstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***
##---
##Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

##Residual standard error: 4.745 on 492 degrees of freedom
##Multiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 
##F-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16
```

 

이 외에도 **summary(lm.fit)$r.sq**를 통해 설명계수를 확인하고, **summary(lm.fit)$sigma**를 통해 RSE를 확인할 수 있다.

#### **다중공선성 확인**

```
library(car)
vif(lm.fit)

##rim       zn    indus     chas      nox       rm      age      dis      rad      tax 
##1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 7.484496 9.008554 
## ptratio    black    lstat 
##1.799084 1.348521 2.941491 
```

#### **설명변수의 비선형 변환**

```
lm.fit2=lm(medv~lstat+I(lstat^2), data=Boston)
summary(lm.fit2)

##Call:
##lm(formula = medv ~ lstat + I(lstat^2), data = Boston)

##Residuals:
##     Min       1Q   Median       3Q      Max 
##-15.2834  -3.8313  -0.5295   2.3095  25.4148 

##Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
##(Intercept) 42.862007   0.872084   49.15   <2e-16 ***
##lstat       -2.332821   0.123803  -18.84   <2e-16 ***
##I(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***
##---
##Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

##Residual standard error: 5.524 on 503 degrees of freedom
##Multiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 
##F-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16
```

 

주어진 설명변수 X에 대해 I(X^2)를 사용하여 설명변수 X^2를 생성하였다.

 

```
lm.fit=lm(medv~lstat, data=Boston)
anova(lm.fit, lm.fit2)

##Analysis of Variance Table

##Model 1: medv ~ lstat
##Model 2: medv ~ lstat + I(lstat^2)
##  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    
##1    504 19472                                 
##2    503 15347  1    4125.1 135.2 < 2.2e-16 ***
##---
##Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 
```

 

anova함수를 이용해 이 두 모델을 비교하는 가설검증을 수행한다다.

귀무가설은 두 모델이 동등하게 데이터를 잘 적합했다는 것이고, 대립가설은 모델2가 더 낫다는 것을 의미한다.

귀무가설을 기각하므로 설명변수 lstat^2까지 포함한 모델이 기존 모델보다 훨씬 낫다는 것을 확인할 수 있다.

 

```
par(mfrow=c(2, 2))
plot(lm.fit2)
```

 



![img](https://blog.kakaocdn.net/dn/dPcDVF/btq2ksgyICt/NvzUkkVUqiKgc5K5QkVHfk/img.png)



 

새로 구축한 모델의 경우 잔차에 구분할 수 있는 패턴이 거의 보이지 않는다는 것을 알 수 있다. 즉 잘 구축된 모델이라는 것 !
